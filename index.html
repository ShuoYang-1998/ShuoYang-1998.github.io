
<!doctype html>
<html>

<head>
<title>Shuo Yang(杨朔)</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Shuo Yang"> 
<meta name="description" content="Shuo's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />



</head>


<body>

<div id="layout-content" style="margin-top:25px">


<table>
	<tbody>
		<tr>
			<td width="50%">
				<div id="toptitle">
					<h1>Shuo Yang 杨朔<h1>
				</div>

                <h3>Postdoctoral Fellow</h3>

		<p>
                    Department of Computer Science</br>
                    The University of Hong Kong </br>
					</br>
                    Email: syang98@hku.hk </br>
		</p>
		<p>
			<a href="https://github.com/shuoyang-1998"><img src="assets/logos/github_logo.png" height="30px"></a>&nbsp;&nbsp;
			<a href="https://scholar.google.com/citations?hl=zh-CN&user=xLsQ02cAAAAJ"><img src="assets/logos/google_logo.png" height="30px"></a>&nbsp;&nbsp;
		</p>
			
			<td width="30%">
				<img src="assets/imgs/me2.jpeg" width="100%"/>
			</td>
			<td width="5%">
				
			</td>
		<tr>
	</tbody>
</table>

<h2>Short Bio</h2>
I am currently a Postdoctoral Fellow at The University of Hong Kong. I got my Ph.D. and Bechelor's degree from University of Technology Sydney and Harbin Institute of Technology in 2023 and 2020, respectively. My research goal is to build efficient and trustworthy AI systems from the perspective of data optimization instead of the traditional model or algorithm optimization approach. I am a recipient of the 2022 Google Ph.D. Fellowship. 



<h2>Selected Publications</h2>

<ul>
	<li>
        <b><font color="black">[ICML 2024]</font></b> &emsp; Mind the Boundary: Coreset Selection via Reconstructing the Decision Boundary<br>
        <b><i>Shuo Yang</i></b>, Zhe Cao, Sheng Guo, Ruiheng Zhang, Ping Luo, Shengping Zhang, Liqiang Nie<br>
	    <p>
        [<a href="" target="_blank" rel="noopener">Paper</a>] 
        </p>
       
    </li>
	<li>
        <b><font color="black">[ICML 2024]</font></b> &emsp; Revisiting Context Aggregation for Image Matting<br>
        Qinglin Liu, Xiaoqian Lv, Quanling Meng, Zonglin Li, Xiangyuan Lan, <b><i>Shuo Yang</i></b>, Shengping Zhang, Liqiang Nie<br>
	    <p>
        [<a href="" target="_blank" rel="noopener">Paper</a>] 
        </p>
       
    </li>
	
	<li>
        <b><font color="black">[SIGIR 2024]</font></b> &emsp; Data-efficient Fine-tuning for LLM-based Recommendation<br>
        Xinyu Lin, Wenjie Wang, Yongqi Li, <b><i>Shuo Yang</i></b>, Fuli Feng, Yinwei Wei, Tat-Seng Chua<br>
	    <p>
        [<a href="https://arxiv.org/pdf/2401.17197" target="_blank" rel="noopener">Paper</a>] 
        </p>
       
    </li>
	<li>
        <b><font color="black">[TNNLS 2024]</font></b> &emsp; Cognition-Driven Structural Prior for Instance-Dependent Label Transition Matrix Estimation<br>
        Ruiheng Zhang, Zhe Cao, <b><i>Shuo Yang#</i></b>, Lingyu Si, Haoyang Sun, Lixin Xu, Fuchun Sun<br>
	    <p>
        [<a href="https://ieeexplore.ieee.org/abstract/document/10382538/" target="_blank" rel="noopener">Paper</a>] 
        </p>
       
    </li>

		<li>
        <b><font color="black">[TPAMI 2023]</font></b> &emsp; A Parametrical Model for Instance-dependent Label Noise<br>
        <b><i>Shuo Yang</i></b>, Songhua Wu, Erkun Yang, Bo Han, Yang Liu, Min Xu, Gang Niu, Tongliang Liu<br>
	    <p>
        [<a href="https://ieeexplore.ieee.org/abstract/document/10209198" target="_blank" rel="noopener">Paper</a>]
          [<a href="https://github.com/ShuoYang-1998/BLTM" rel="noopener">Code</a>] 
        </p>
       
    </li>
	
	<li>
        <b><font color="black">[CVPR 2023]</font></b> &emsp; BiCro: Noisy Correspondence Rectification for Multi-modality Data via Bi-directional Cross-modal Similarity Consistency<br>
        <b><i>Shuo Yang</i></b>, Zhaopan Xu, Kai Wang, Yang You, Hongxun Yao, Tongliang Liu, Min Xu<br>
        <p>
          [<a href="https://arxiv.org/abs/2303.12419" target="_blank" rel="noopener">Paper</a>] 
	  [<a href="https://github.com/xu5zhao/BiCro" target="_blank" rel="noopener">Code</a>] 
        </p>
    </li>
 <li>
        <b><font color="black">[ICLR 2023]</font></b> &emsp; Dataset Pruning: Reducing Training Data by Examining Generalization Influence<br>
        <b><i>Shuo Yang</i></b>, Zeke Xie, Hanyu Peng, Min Xu, Mingming Sun, Ping Li<br>
        <p>
          [<a href="https://openreview.net/pdf?id=4wZiAXD29TQ" target="_blank" rel="noopener">Paper</a>] 
	  [<a href="assets/code/code_datasetptuning.zip" rel="noopener">Code</a>] 
        </p>
    </li>
   <li>
        <b><font color="black">[T-MM 2023]</font></b> &emsp; Unsupervised Unified Image Dehazing and Denoising Network for Single Hazy Image Enhancement<br>
        Bosheng Ding, Ruiheng Zhang, Lixin Xu, Guanyu Liu, <b><i>Shuo Yang</i></b>, Yumeng Liu, Qi Zhang<br>
	  [<a href="https://ieeexplore.ieee.org/document/10086612" target="_blank" rel="noopener">Paper</a>] 
	   
        
    </li>

 <li>
        <b><font color="black">[ECCV 2022]</font></b> &emsp;PartImageNet: A Large, High-Quality Dataset of Parts<br>
        Ju He, <b><i>Shuo Yang</i></b>, Shaokang Yang, Adam Kortylewski, Xiaoding Yuan, Jie-Neng Chen, Shuai Liu, Cheng Yang, Alan Yuille<br>
	 	<p>
          [<a href="https://arxiv.org/pdf/2112.00933.pdf" target="_blank" rel="noopener">Paper</a>]
          [<a href="https://github.com/TACJu/PartImageNet" target="_blank" rel="noopener">Code</a>] 
        </p>
         
    </li>
    <li>
        <b><font color="black">[ICML 2022]</font></b> &emsp; Estimating Instance-dependent Bayes-label Transition Matrix using a Deep Neural Network<br>
        <b><i>Shuo Yang</i></b>, Erkun Yang, Bo Han, Yang Liu, Min Xu, Gang Niu, Tongliang Liu<br>
	    <p>
          [<a href="https://arxiv.org/pdf/2105.13001" target="_blank" rel="noopener">Paper</a>]
          [<a href="https://github.com/ShuoYang-1998/BLTM" rel="noopener">Code</a>] 
        </p>
       
    </li>
	
    <li>
        <b><font color="black">[CVPR 2022]</font></b> &emsp; CAFE: Learning to Condense Dataset by Aligning Features<br>
        Kai Wang, Bo Zhao, Zheng Zhu, Xiangyu Peng, <b><i>Shuo Yang</i></b>, Hakan Bilen, Guan Huang, Xinchao Wang, Yang You<br>
		<p>
          [<a href="https://arxiv.org/abs/2203.01531" target="_blank" rel="noopener">Paper</a>]
          [<a href="https://github.com/kaiwang960112/CAFE" rel="noopener">Code</a>] 
        </p>
    </li>

    
    <li>
        <b><font color="black">[ICLR 2022]</font></b> &emsp; Objects in Semantic Topology<br>
        <b><i>Shuo Yang</i></b>, Peize Sun, Yi Jiang, Xiaobo Xia, Ruiheng Zhang, Zehuan Yuan, Changhu Wang, Ping Luo, Min Xu<br>
        <p>
          [<a href="https://arxiv.org/pdf/2110.02687" target="_blank" rel="noopener">Paper</a>]
          [<a href="assets/code/objects_code.zip" rel="noopener">Code</a>] 
        </p>
    </li>

   <li>
        <b><font color="black">[T-PAMI 2021]</font></b> &emsp; Bridging the Gap between Few-Shot Learning and Many-Shot Learning via Distribution Calibration<br>
        <b><i>Shuo Yang</i></b>, Songhua Wu, Tongliang Liu, Min Xu<br>
        <p>
          [<a href="https://ieeexplore.ieee.org/document/9634045/" target="_blank" rel="noopener">Paper</a>]
          [<a href="https://github.com/ShuoYang-1998/Few_Shot_Distribution_Calibration" rel="noopener">Code</a>] 
        </p>
    </li>

    <li>
        <b><font color="black">[ICLR 2021] <b><font color="red">[Oral]</font></b></font></b> &emsp; Free Lunch for Few-shot Learning: Distribution Calibration<br>
        <b><i>Shuo Yang</i></b>, Lu Liu, Min Xu<br>
        <p>
          [<a href="https://arxiv.org/pdf/2101.06395" target="_blank" rel="noopener">Paper</a>]
          [<a href="https://github.com/ShuoYang-1998/Few_Shot_Distribution_Calibration" rel="noopener">Code</a>] 
        </p>
    </li>

    <li>
        <b><font color="black">[CVPR 2021]</font></b> &emsp; Single-view 3D Object Reconstruction from Shape Priors in Memory<br>
        <b><i>Shuo Yang</i></b>, Min Xu, Haozhe Xie, Stuart Perry, Jiahao Xia<br>
        <p>
          [<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Single-View_3D_Object_Reconstruction_From_Shape_Priors_in_Memory_CVPR_2021_paper.html" target="_blank" rel="noopener">Paper</a>]
<!--           [<a href="" rel="noopener">Code</a>]  -->
        </p>
    </li>
    <li>
        <b><font color="black">[ACM MM 2019]</font></b> &emsp; Adaptive Semantic-Visual Tree for Hierarchical Embeddings<br>
        <b><i>Shuo Yang</i></b>, Wei Yu, Ying Zheng, Tao Mei, Hongxun Yao<br>
        <p>
          [<a href="https://arxiv.org/pdf/2003.03707" target="_blank" rel="noopener">Paper</a>]
        </p>
    </li>
    
    

    
</ul>

<!-- <h2>Selected Preprints</h2>
<ul>

<li>
<b><font color="black">[arXiv 2023]</font></b> &emsp; Large-scale Dataset Pruning with Dynamic Uncertainty<br>
Muyang He, <b><i>Shuo Yang</i></b>, Tiejun Huang, Bo Zhao<br>
<p>
  [<a href="https://arxiv.org/abs/2306.05175" target="_blank" rel="noopener">Paper</a>]
  [<a href="https://github.com/BAAI-DCAI/Dataset-Pruning" rel="noopener">Code</a>] 
</p>

    </li>
  
    <li>
        <b><font color="black">[arXiv 2022]</font></b> &emsp; Reliable Label Correction is a Good Booster When Learning with Extremely Noisy Labels<br>
        Kai Wang, Xiangyu Peng, <b><i>Shuo Yang</i></b>, Jianfei Yang, Zheng Zhu, Xinchao Wang, Yang You<br>
        <p>
          [<a href="https://arxiv.org/abs/2205.00186" target="_blank" rel="noopener">Paper</a>]
          [<a href="https://github.com/xyupeng/LC-Booster" rel="noopener">Code</a>] 
        </p>

    </li>
     -->
    
    

   
    
	
</ul>
<h2>Education</h2>

<ul>
    <li>
        <p> 
                        <strong>Ph.D. student</strong>, 2020.08 - 2023.11 <br>
                        University of Technology Sydney, Australia, advised by A/Prof.<a href="https://profiles.uts.edu.au/Min.Xu" target="_blank"> Min Xu</a>
                    </p>
   </li>
   <li>
        <p> 
                        <strong>B.Eng.</strong>, 2016.08 - 2020.06 <br>
                        Harbin Institute of Technology, Harbin, China,
                        advised by Prof.<a href="https://scholar.google.com.hk/citations?user=aOMFNFsAAAAJ&hl=en&oi=ao"> Hongxun Yao</a>
                    </p>
   </li>
</ul>


<h2>Honors and Awards</h2>

<ul>
<li>
        UTS Chancellor's Award (The best Ph.D. thesis award, 1 recipient per year), 2023
    </li>
	<li>
        Chinese Government Award for Outstanding Self-financed Students Abroad (The highest award granted by the Chinese government to Chinese students overseas, 650 recipients per year), 2023
    </li>
<li>
        Google Ph.D. Fellowship (9 recipients world-wide), Google, 2022
    </li>
    <li>
        Outstanding Intern of the Year, Baidu Research, 2022
    </li>
	
<!--     <li>
        International Research Scholarship, UTS, 2020 - 2024
    </li> -->
    <li>
        Star Intern Award, JD AI Research, 2019
    </li>
    <li>
        The People's Scholarship in China, 2018
    </li>
    <li>
        The People's Scholarship in China, 2017
    </li>
    
    
</ul>

<h2>Academic Services</h2>

<ul>
    <li>
        Reviewer: ICLR, NeurIPS, ICML, ICCV, CVPR, ECCV   
    </li>
   <li>
        Program Committee Member: IJCAI, AAAI
    </li>
</ul>
<div style='width:600px;height:300px;margin:0 auto'>
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=SLuXY0zBV43uNA9eAKs3Um8u4rSJ2hu4jngB_QhBYRU'></script>
    </div>

<table width="100%"> 
	<tr> 
		<td align="center">&copy; Shuo Yang | Last update: March 2024</td>
	</tr> 
</table>

</div>
</body>
</html>
